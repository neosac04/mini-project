{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c1f081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.environ['Groq_APIKey']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eac88a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#College Info for Engineering Colleges\n",
      "\n",
      "College 1: BMS College of Engineering\n",
      "\n",
      "BMS College Overview Duration 4 years\n",
      "\n",
      "Course Level UG Degree\n",
      "\n",
      "Mode of Course Full Time\n",
      "\n",
      "Total Tuition Fees INR 18.00 Lakh\n",
      "\n",
      "Type of Univers ity Private,Autonomous\n",
      "\n",
      "BMS Col\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Path to all .md files in the folder\n",
    "markdown_path = \"CollegeInfo/allinfo.md\"\n",
    "loader = UnstructuredMarkdownLoader(markdown_path)\n",
    "\n",
    "data = loader.load()\n",
    "assert len(data) == 1\n",
    "assert isinstance(data[0], Document)\n",
    "readme_content = data[0].page_content\n",
    "print(readme_content[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433b2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b7433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_29356\\3087069557.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\rohan\\miniconda3\\envs\\LangchainRAG\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load a local embedding model from Hugging Face\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create your vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d35af",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Collection' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Collection' object is not callable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(vectorstore._collection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8fbf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b07edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rohan\\miniconda3\\envs\\LangchainRAG\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608111e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4d80056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c8734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ed9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_29356\\4254395850.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama3-70b-8192\",  # or use \"llama3-70b-8192\"\n",
    "    openai_api_key=\"\",\n",
    "    openai_api_base=\"https://api.groq.com/openai/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "016260a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "retriever =vectorstore.as_retriever()\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3ffe714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided data, here are three engineering course recommendations for a student interested in maths and physics with a general rank of 1500:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"Course Recommendations\": [\n",
      "    {\n",
      "      \"Course Name\": \"B.E. in Computer Science and Engineering\",\n",
      "      \"College\": \"MSRIT College\",\n",
      "      \"Cutoff Rank (General)\": 1125 (2022), 1171 (2023), 1626 (2024),\n",
      "      \"Average Cutoff Rank\": 1311\n",
      "    },\n",
      "    {\n",
      "      \"Course Name\": \"B.Tech. in Electronics and Communication Engineering\",\n",
      "      \"College\": \"PES College\",\n",
      "      \"Cutoff Rank (General)\": 16146 (2022), 3803 (2023), 8391 (2024),\n",
      "      \"Average Cutoff Rank\": 9250\n",
      "    },\n",
      "    {\n",
      "      \"Course Name\": \"B.E. in Electrical and Electronics Engineering\",\n",
      "      \"College\": \"MSRIT College\",\n",
      "      \"Cutoff Rank (General)\": 9893 (2022), 7763 (2023), 9339 (2024),\n",
      "      \"Average Cutoff Rank\": 8998\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The average cutoff rank is calculated by taking the average of the cutoff ranks for the three years (2022, 2023, and 2024).\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"query\": \"In JSON format, Recommend 3 engineering courses offered by engineering colleges for a student who's intersted in maths and physics and has a general rank 0f 1500, calculate and include an average the cutoff pf the course you have selected. If any data is ambiguous, leave it and answer the rest of the question instead\"})\n",
    "print(response['result'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangchainRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
